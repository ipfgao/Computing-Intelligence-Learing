{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 题目1：设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "人类活动语法='''\n",
    "人类活动 = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "接待语法='''\n",
    "接待 = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "确认语法='''\n",
    "确认 = 肯定  | 多次否定\n",
    "肯定 = 好 | 可以 | 行\n",
    "否定 =  不 | 算了 | 换一个项目吧\n",
    "多次否定 = 否定 , 多次否定 |否定 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def 生成程序(语法,目标):\n",
    "    if 目标 in 语法:\n",
    "        选项范围=语法[目标] #选项范围为语法中含有目标项的那一行\n",
    "        选项=random.choice(选项范围)\n",
    "        return ''.join(生成程序(语法,目标=c.strip()) for c in 选项.split())\n",
    "    else:\n",
    "        return 目标\n",
    "def 由语法生成程序(语法文本,目标,赋值分隔符,并列分隔符):\n",
    "    语法 = dict() #key is the @statement（表示左边需要展开的）,value is @expression（表示右边展开的内容）\n",
    "    for line in 语法文本.split('\\n'):\n",
    "        if not line:continue\n",
    "        #跳过空行\n",
    "        ##？？需要一个判断语句，来确定是否使用了合理的分隔符??\n",
    "        前项,后项=line.split(赋值分隔符)\n",
    "        #以 = 为界进行分割，分割成 前项 和 后项 两个部分\n",
    "        语法[前项.strip()]=后项.split(并列分隔符)\n",
    "        #逐行将后项的并列项分割后，赋予前项。前项.strip()是为了去掉其的空格\n",
    "    _程序_=生成程序(语法,目标)\n",
    "    return _程序_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 人类活动():\n",
    "    return 由语法生成程序(人类活动语法,'人类活动','=','|')\n",
    "def 接待():\n",
    "    return 由语法生成程序(接待语法,'接待','=','|')\n",
    "def 确认():\n",
    "    return 由语法生成程序(确认语法,'确认','=','|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成多句话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "接待段子语法='''\n",
    "人类：人类活动\n",
    "接待员：接待\n",
    "人类1：确认\n",
    "人类2：确认\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 生成段子(段子语法):\n",
    "    for line in 段子语法.split('\\n'):\n",
    "        if not line:continue\n",
    "        动作执行人,动作=line.split('：')\n",
    "        print(动作执行人+\"：\"+eval(动作+'()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人类：俺想找点乐子\n",
      "接待员：您好我是9号,您需要耍一耍打牌吗？\n",
      "人类1：不\n",
      "人类2：算了\n"
     ]
    }
   ],
   "source": [
    "生成段子(接待段子语法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 题目2 ：使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '/home/ipfgao/Computing-Intelligence/datasource/movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = open(corpus).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅保留数字和汉字\n",
    "def remove_others(s):    \n",
    "    return re.sub(r'[^0-9\\u4e00-\\u9fa5]', '', s)\n",
    "\n",
    "# 删除多余的空白(including spaces, tabs, line breaks)'''\n",
    "def remove_whitespaces(s):\n",
    "    return re.sub(r'\\s{2,}', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT=remove_whitespaces(remove_others(FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 2.566 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "TOKENS = cut(TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_words = [\n",
    "    TOKENS[i] + TOKENS[i+1] for i in range(len(TOKENS)-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_word_counts = Counter(_2_gram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_word_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1_gram_count(word):\n",
    "    if word in words_count: return words_count[word]\n",
    "    else:\n",
    "        return words_count.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_gram_count(word):\n",
    "    if word in _2_gram_word_counts: return _2_gram_word_counts[word]\n",
    "    else:\n",
    "        return _2_gram_word_counts.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gram_count(word, wc):\n",
    "    if word in wc: return wc[word]\n",
    "    else:\n",
    "        return wc.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gram_count('保险',words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gram_count('卖保险', _2_gram_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_gram_model(sentence):\n",
    "    # 2-gram langauge model\n",
    "    tokens = cut(sentence)\n",
    "    \n",
    "    probability = 1\n",
    "    \n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        \n",
    "        _two_gram_c = get_gram_count(word+next_word, _2_gram_word_counts)\n",
    "        _one_gram_c = get_gram_count(next_word, words_count)\n",
    "        pro =  _two_gram_c / _one_gram_c\n",
    "        \n",
    "        probability *= pro\n",
    "    \n",
    "    return probability  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_gram_model('险保')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_gram_model('错误的概率为什么比正确还要高')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_gram_model('的房间卡洛斯的解放了看见爱上')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "简单句语法 = '''\n",
    "句子 => 名词短语 动词短语\n",
    "名词短语 => 量词 形容词* 名词\n",
    "形容词* => 形容词 | 形容词 形容词*\n",
    "动词短语 => 动词 名词短语\n",
    "量词 =>  一个 | 这个\n",
    "名词 =>   女人 |  篮球 | 桌子 | 小猫\n",
    "动词 => 看着   |  坐在 |  听着 | 看见\n",
    "形容词 =>   蓝色的 |  好看的 | 小小的'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 生成最佳语句(语法文本,目标,赋值分隔符,并列分隔符,随机次数): # you code here\n",
    "    语句和其概率表=[]\n",
    "    for  i  in range(随机次数):\n",
    "        语句=由语法生成程序(语法文本,目标,赋值分隔符,并列分隔符)\n",
    "        语句出现的概率=two_gram_model(语句)\n",
    "        语句和其概率表.append((语句出现的概率,语句))    \n",
    "    return max(语句和其概率表)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "生成最佳语句(简单句语法,'句子','=>','|',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存在的问题：\n",
    "1、two_gram_model并不能筛选出最佳的语句\n",
    "2、语料库太大的话，运行效率太低，运算时间长\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
